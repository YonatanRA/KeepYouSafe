{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detector de mascara sanitaria I (entrenamiento)\n",
    "\n",
    "Vamos a preparar un detector de mascara con TensorFlow y OpenCV. Primero necesitamos entrenar el modelo con imagenes de caras con y sin mascara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerias\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import classification_report as report\n",
    "\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constantes, tasa de aprendizaje, epocas de entrenamiento y tamaño de la muestra\n",
    "\n",
    "TASA_APRENDIZAJE=1e-4\n",
    "EPOCAS=20\n",
    "BATCH_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando imagenes...\n",
      "\n",
      "Cargadas.\n"
     ]
    }
   ],
   "source": [
    "# lee la lista de imagenes del dataset\n",
    "\n",
    "print('Cargando imagenes...')\n",
    "\n",
    "imagenes=list(paths.list_images('dataset'))\n",
    "\n",
    "print('\\nCargadas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "etiquetas=[]\n",
    "\n",
    "for e in imagenes:\n",
    "    # extrae la etiqueta del nombre del archivo\n",
    "    etiqueta=e.split(os.path.sep)[-2]\n",
    "\n",
    "    # carga la imagen (224x224) y procesala\n",
    "    imagen=load_img(e, target_size=(224, 224))\n",
    "    imagen=img_to_array(imagen)\n",
    "    imagen=preprocess_input(imagen)\n",
    "\n",
    "    # añade a la lista\n",
    "    data.append(imagen)\n",
    "    etiquetas.append(etiqueta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se convierten datos y etiquetas a arrays de numpy\n",
    "\n",
    "data=np.array(data, dtype='float32')\n",
    "etiquetas=np.array(etiquetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  one-hot encoding para etiquetas\n",
    "\n",
    "_bin=LabelBinarizer()\n",
    "\n",
    "etiquetas=_bin.fit_transform(etiquetas)\n",
    "etiquetas=to_categorical(etiquetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "\n",
    "X_train, X_test, y_train, y_test=tts(data, etiquetas, test_size=.2, stratify=etiquetas, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aumenta datos con el generador de imagenes\n",
    "\n",
    "img_gen=ImageDataGenerator(rotation_range=20, zoom_range=.15,\n",
    "                           width_shift_range=.2, height_shift_range=.2,\n",
    "                           shear_range=.15, horizontal_flip=True,\n",
    "                           fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo**\n",
    "\n",
    "Se creara el modelo con MobileNetV2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "# se carga MobileNetV2 sin el clasificador\n",
    "modelo_base=MobileNetV2(weights='imagenet', \n",
    "                        include_top=False, \n",
    "                        input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "\n",
    "# se contruye el nuevo clasificador\n",
    "modelo_x=modelo_base.output\n",
    "modelo_x=AveragePooling2D(pool_size=(7, 7))(modelo_x)\n",
    "modelo_x=Flatten(name='flatten')(modelo_x)\n",
    "modelo_x=Dense(128, activation=\"relu\")(modelo_x)\n",
    "modelo_x=Dropout(.5)(modelo_x)\n",
    "modelo_x=Dense(2, activation='softmax')(modelo_x)\n",
    "\n",
    "\n",
    "\n",
    "# se pone todo junto\n",
    "modelo=Model(inputs=modelo_base.input, outputs=modelo_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilando modelo...\n",
      "Compilado.\n"
     ]
    }
   ],
   "source": [
    "# se congela el entrenamiento del modelo base\n",
    "for capa in modelo_base.layers:\n",
    "    capa.trainable=False\n",
    "\n",
    "# se compila el modelo\n",
    "print('Compilando modelo...')\n",
    "\n",
    "optimizador=Adam(lr=TASA_APRENDIZAJE, decay=TASA_APRENDIZAJE/EPOCAS)\n",
    "\n",
    "modelo.compile(loss='binary_crossentropy', optimizer=optimizador, metrics=['accuracy'])\n",
    "\n",
    "print('Compilado.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n",
      "Epoch 1/20\n",
      "96/96 [==============================] - 68s 712ms/step - loss: 0.3342 - accuracy: 0.8551 - val_loss: 0.1194 - val_accuracy: 0.9649\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 69s 717ms/step - loss: 0.1237 - accuracy: 0.9547 - val_loss: 0.0796 - val_accuracy: 0.9740\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 66s 690ms/step - loss: 0.0766 - accuracy: 0.9747 - val_loss: 0.0680 - val_accuracy: 0.9792\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 67s 695ms/step - loss: 0.0659 - accuracy: 0.9780 - val_loss: 0.0577 - val_accuracy: 0.9766\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 65s 681ms/step - loss: 0.0560 - accuracy: 0.9813 - val_loss: 0.0514 - val_accuracy: 0.9818\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 65s 682ms/step - loss: 0.0566 - accuracy: 0.9819 - val_loss: 0.0525 - val_accuracy: 0.9766\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 67s 699ms/step - loss: 0.0469 - accuracy: 0.9839 - val_loss: 0.0504 - val_accuracy: 0.9766\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 66s 691ms/step - loss: 0.0485 - accuracy: 0.9826 - val_loss: 0.0421 - val_accuracy: 0.9844\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 69s 717ms/step - loss: 0.0434 - accuracy: 0.9855 - val_loss: 0.0374 - val_accuracy: 0.9883\n",
      "Epoch 10/20\n",
      "96/96 [==============================] - 67s 701ms/step - loss: 0.0355 - accuracy: 0.9898 - val_loss: 0.0366 - val_accuracy: 0.9870\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 67s 703ms/step - loss: 0.0335 - accuracy: 0.9869 - val_loss: 0.0393 - val_accuracy: 0.9857\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 65s 679ms/step - loss: 0.0310 - accuracy: 0.9882 - val_loss: 0.0336 - val_accuracy: 0.9909\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 65s 681ms/step - loss: 0.0309 - accuracy: 0.9901 - val_loss: 0.0335 - val_accuracy: 0.9909\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 66s 683ms/step - loss: 0.0328 - accuracy: 0.9882 - val_loss: 0.0365 - val_accuracy: 0.9857\n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 66s 687ms/step - loss: 0.0303 - accuracy: 0.9895 - val_loss: 0.0309 - val_accuracy: 0.9909\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 66s 684ms/step - loss: 0.0309 - accuracy: 0.9908 - val_loss: 0.0313 - val_accuracy: 0.9896\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 66s 692ms/step - loss: 0.0241 - accuracy: 0.9918 - val_loss: 0.0291 - val_accuracy: 0.9896\n",
      "Epoch 18/20\n",
      "96/96 [==============================] - 68s 710ms/step - loss: 0.0245 - accuracy: 0.9905 - val_loss: 0.0316 - val_accuracy: 0.9883\n",
      "Epoch 19/20\n",
      "96/96 [==============================] - 68s 707ms/step - loss: 0.0222 - accuracy: 0.9924 - val_loss: 0.0283 - val_accuracy: 0.9896\n",
      "Epoch 20/20\n",
      "96/96 [==============================] - 67s 701ms/step - loss: 0.0214 - accuracy: 0.9928 - val_loss: 0.0273 - val_accuracy: 0.9909\n",
      "Entrenado.\n"
     ]
    }
   ],
   "source": [
    "# se entrena el clasificador con las imagenes\n",
    "\n",
    "print('Entrenando modelo...')\n",
    "\n",
    "historico=modelo.fit(img_gen.flow(X_train, y_train, batch_size=BATCH_SIZE), \n",
    "           steps_per_epoch=len(X_train)//BATCH_SIZE,\n",
    "           validation_data=(X_test, y_test), \n",
    "           validation_steps=len(X_test)//BATCH_SIZE, \n",
    "           epochs=EPOCAS)\n",
    "\n",
    "print('Entrenado.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " con_mascara       0.99      0.99      0.99       384\n",
      " sin_mascara       0.99      0.99      0.99       386\n",
      "\n",
      "    accuracy                           0.99       770\n",
      "   macro avg       0.99      0.99      0.99       770\n",
      "weighted avg       0.99      0.99      0.99       770\n",
      "\n",
      "Guardando modelo en h5...\n",
      "Guardado\n"
     ]
    }
   ],
   "source": [
    "# haciendo predicciones\n",
    "preds=modelo.predict(X_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "# la mayor prob de pertenencia\n",
    "preds=np.argmax(preds, axis=1)\n",
    "\n",
    "# reporte de clasificacion\n",
    "print(report(y_test.argmax(axis=1), preds, target_names=_bin.classes_))\n",
    "\n",
    "# guardar h5\n",
    "print('Guardando modelo en h5...')\n",
    "modelo.save('detector_mascara.model', save_format='h5')\n",
    "print('Guardado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-69d8419ddaa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ggplot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCAS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCAS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCAS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train_acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot de perdida y acierto entrenamiento y validacion\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, EPOCAS), historico.history['loss'], label='train_loss')\n",
    "plt.plot(np.arange(0, EPOCAS), historico.history['val_loss'], label='val_loss')\n",
    "plt.plot(np.arange(0, EPOCAS), historico.history['acc'], label='train_acc')\n",
    "plt.plot(np.arange(0, EPOCAS), historico.history['val_acc'], label='val_acc')\n",
    "\n",
    "plt.title('Acierto y perdida')\n",
    "plt.xlabel('#Epocas')\n",
    "plt.ylabel('Perdida/Acierto')\n",
    "plt.legend(loc='best')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
