{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detector Distancia Social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerias\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import imutils\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from math import pow, sqrt\n",
    "from imutils.video import FPS\n",
    "from imutils.video import VideoStream\n",
    "\n",
    "from flask import Flask, render_template, Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen():\n",
    "#Loading Caffe Model\n",
    "    print('[Status] Loading Model...')\n",
    "    nn = cv2.dnn.readNetFromCaffe('SSD_MobileNet_prototxt.txt', 'SSD_MobileNet.caffemodel')\n",
    "\n",
    "#Initialize Video Stream (Use src = 0 for Webcam or src = 'path to video input')\n",
    "    print('[Status] Starting Video Stream...')\n",
    "    vs = VideoStream(src = 0).start()\n",
    "    #time.sleep(0.1)\n",
    "    fps = FPS().start()\n",
    "\n",
    "#Loop Video Stream\n",
    "    while True:\n",
    "    \n",
    "    #Resize Frame to 600 pixels\n",
    "        frame = vs.read()\n",
    "        frame = imutils.resize(frame, width=600)\n",
    "\n",
    "    #Converting Frame to Blob\n",
    "        (h, w) = frame.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 0.007843, (300, 300), 127.5)\n",
    "\n",
    "    #Passing Blob through network to detect and predict\n",
    "        nn.setInput(blob)\n",
    "        detections = nn.forward()\n",
    "\n",
    "    #Setting Focal Length\n",
    "        F = 615\n",
    "        pos = {}\n",
    "        coordinates = {}\n",
    "\n",
    "        \n",
    "    #Loop over the detections\n",
    "        for i in np.arange(0, detections.shape[2]):\n",
    "\n",
    "        #Extracting the confidence of predictions\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        #Filtering out weak predictions\n",
    "            if confidence > 0.5:\n",
    "\n",
    "            #Extracting the index of the labels from the detection\n",
    "                object_id = int(detections[0, 0, i, 1])\n",
    "\n",
    "            #Identifying only Person as Detected Object\n",
    "                if(object_id == 15):\n",
    "                    \n",
    "                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                    (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "                #Draw the prediction on the frame\n",
    "                    label = \"Person: {:.2f}%\".format(confidence * 100)\n",
    "                    cv2.rectangle(frame, (startX, startY), (endX, endY), (10,255,0), 2)\n",
    "                    y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "                    cv2.putText(frame, label, (startX, y), cv2.FONT_HERSHEY_DUPLEX, 0.5, (20,255,0), 1)\n",
    "\n",
    "                    coordinates[i] = (startX, startY, endX, endY)\n",
    "\n",
    "                #Mid point of bounding box\n",
    "                    midOfX = round((startX+endX)/2,4)\n",
    "                    midOfY = round((startY+endY)/2,4)\n",
    "\n",
    "                    ht = round(endY-startY,4)\n",
    "\n",
    "                 #Distance from camera based on triangle similarity\n",
    "                    distance = (F * 165)/ht\n",
    "                    \n",
    "                 #Mid-point of bounding boxes (in cm) based on triangle similarity\n",
    "                    midOfX_cm = (midOfX * distance) / F\n",
    "                    midOfY_cm = (midOfY * distance) / F\n",
    "                    pos[i] = (midOfX_cm, midOfY_cm, distance)\n",
    "                    \n",
    "        proximity = []\n",
    "\n",
    "        #Looping over positions of bounding boxes in frame\n",
    "        for i in pos.keys():\n",
    "            \n",
    "            for j in pos.keys():\n",
    "\n",
    "                if i < j:\n",
    "                    dist = sqrt(pow(pos[i][0] - pos[j][0],2) + pow(pos[i][1] - pos[j][1],2) + pow(pos[i][2] - pos[j][2],2))\n",
    "\n",
    "                #Checking threshold distance - 175 cm\n",
    "                    if dist < 175:\n",
    "                        \n",
    "                        proximity.append(i)\n",
    "                        proximity.append(j)\n",
    "\n",
    "                        warning_label = \"Maintain Safe Distance. Move away!\"\n",
    "                        cv2.putText(frame, warning_label, (50,50), cv2.FONT_HERSHEY_DUPLEX, 0.5, color, 1)\n",
    "            \n",
    "                        \n",
    "        for i in pos.keys():\n",
    "            \n",
    "            if i in proximity:\n",
    "\n",
    "                color = [0,0,255]\n",
    "\n",
    "            else:\n",
    "                color = [0,255,0]\n",
    "                \n",
    "            (x, y, w, h) = coordinates[i]\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (w, h), color, 2)\n",
    "                            \n",
    "\n",
    "        frame = cv2.imencode('.jpg', frame)[1].tobytes()\n",
    "        yield (b'--frame\\r\\n'b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
    "\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "        fps.update()\n",
    "\n",
    "    fps.stop()\n",
    "    print(\"[INFO]Elapsed time: {:.2f}\".format(fps.elapsed()))\n",
    "    print(\"[INFO]Approx. FPS:  {:.2f}\".format(fps.fps()))\n",
    "\n",
    "\n",
    "\n",
    "def video_feed():\n",
    "    #Video streaming route. Put this in the src attribute of image tag in html code\n",
    "    return Response(gen(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object gen at 0x7f058adbf040>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response streamed [200 OK]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_feed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Status] Loading Model...\n",
      "[Status] Starting Video Stream...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8a6f7a2c42ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#Resize Frame to 600 pixels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#Converting Frame to Blob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/imutils/convenience.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, width, height, inter)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# grab the image size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# if both the width and height are None, then return the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "while 1:\n",
    "    print('[Status] Loading Model...')\n",
    "    nn = cv2.dnn.readNetFromCaffe('SSD_MobileNet_prototxt.txt', 'SSD_MobileNet.caffemodel')\n",
    "\n",
    "\n",
    "#Initialize Video Stream (Use src = 0 for Webcam or src = 'path to video input')\n",
    "    print('[Status] Starting Video Stream...')\n",
    "    vs = VideoStream(src = 0).start()\n",
    "    #time.sleep(0.1)\n",
    "    fps = FPS().start()\n",
    "\n",
    "#Loop Video Stream\n",
    "    while True:\n",
    "    \n",
    "    #Resize Frame to 600 pixels\n",
    "        frame = vs.read()\n",
    "        frame = imutils.resize(frame, width=600)\n",
    "\n",
    "    #Converting Frame to Blob\n",
    "        (h, w) = frame.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 0.007843, (300, 300), 127.5)\n",
    "\n",
    "    #Passing Blob through network to detect and predict\n",
    "        nn.setInput(blob)\n",
    "        detections = nn.forward()\n",
    "\n",
    "    #Setting Focal Length\n",
    "        F = 615\n",
    "        pos = {}\n",
    "        coordinates = {}\n",
    "\n",
    "        \n",
    "    #Loop over the detections\n",
    "        for i in np.arange(0, detections.shape[2]):\n",
    "\n",
    "        #Extracting the confidence of predictions\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        #Filtering out weak predictions\n",
    "            if confidence > 0.5:\n",
    "\n",
    "            #Extracting the index of the labels from the detection\n",
    "                object_id = int(detections[0, 0, i, 1])\n",
    "\n",
    "            #Identifying only Person as Detected Object\n",
    "                if(object_id == 15):\n",
    "                    \n",
    "                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                    (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "                #Draw the prediction on the frame\n",
    "                    label = \"Person: {:.2f}%\".format(confidence * 100)\n",
    "                    cv2.rectangle(frame, (startX, startY), (endX, endY), (10,255,0), 2)\n",
    "                    y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "                    cv2.putText(frame, label, (startX, y), cv2.FONT_HERSHEY_DUPLEX, 0.5, (20,255,0), 1)\n",
    "\n",
    "                    coordinates[i] = (startX, startY, endX, endY)\n",
    "\n",
    "                #Mid point of bounding box\n",
    "                    midOfX = round((startX+endX)/2,4)\n",
    "                    midOfY = round((startY+endY)/2,4)\n",
    "\n",
    "                    ht = round(endY-startY,4)\n",
    "\n",
    "                 #Distance from camera based on triangle similarity\n",
    "                    distance = (F * 165)/ht\n",
    "                    \n",
    "                 #Mid-point of bounding boxes (in cm) based on triangle similarity\n",
    "                    midOfX_cm = (midOfX * distance) / F\n",
    "                    midOfY_cm = (midOfY * distance) / F\n",
    "                    pos[i] = (midOfX_cm, midOfY_cm, distance)\n",
    "                    \n",
    "        proximity = []\n",
    "\n",
    "        #Looping over positions of bounding boxes in frame\n",
    "        for i in pos.keys():\n",
    "            \n",
    "            for j in pos.keys():\n",
    "\n",
    "                if i < j:\n",
    "                    dist = sqrt(pow(pos[i][0] - pos[j][0],2) + pow(pos[i][1] - pos[j][1],2) + pow(pos[i][2] - pos[j][2],2))\n",
    "\n",
    "                #Checking threshold distance - 175 cm\n",
    "                    if dist < 175:\n",
    "                        \n",
    "                        proximity.append(i)\n",
    "                        proximity.append(j)\n",
    "\n",
    "                        warning_label = \"Maintain Safe Distance. Move away!\"\n",
    "                        cv2.putText(frame, warning_label, (50,50), cv2.FONT_HERSHEY_DUPLEX, 0.5, color, 1)\n",
    "            \n",
    "                        \n",
    "        for i in pos.keys():\n",
    "            \n",
    "            if i in proximity:\n",
    "\n",
    "                color = [0,0,255]\n",
    "\n",
    "            else:\n",
    "                color = [0,255,0]\n",
    "                \n",
    "            (x, y, w, h) = coordinates[i]\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (w, h), color, 2)\n",
    "                            \n",
    "\n",
    "        frame = cv2.imencode('.jpg', frame)[1].tobytes()\n",
    "        #yield (b'--frame\\r\\n'b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
    "\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "        fps.update()\n",
    "\n",
    "    fps.stop()\n",
    "    print(\"[INFO]Elapsed time: {:.2f}\".format(fps.elapsed()))\n",
    "    print(\"[INFO]Approx. FPS:  {:.2f}\".format(fps.fps()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
